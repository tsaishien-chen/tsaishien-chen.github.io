<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Tsai-Shien Chen - Ph.D. Candidate at UC Merced specializing in Deep Learning for Computer Vision and Generative Models">
    <meta name="keywords" content="Tsai-Shien Chen, Deep Learning, Computer Vision, Generative Models, Video Synthesis">
    <meta name="google-site-verification" content="eGDOZ_6azobM9Vcl7r072IFo1FJ-TfNvGkmz6YbLCLo">
    
    <title>Tsai-Shien Chen</title>
    
    <link rel="shortcut icon" href="data/images/icon/graduate.png">
    <link rel="canonical" href="https://tsaishien-chen.github.io/">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css">
    <link rel="stylesheet" href="assets/main.css">
    
    <script nonce="gtm-script">
        (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-K5ZTMW');
    </script>
</head>

<body>
    <noscript>
        <iframe src="//www.googletagmanager.com/ns.html?id=GTM-K5ZTMW" 
                height="0" width="0" style="display:none;visibility:hidden"></iframe>
    </noscript>

    <header class="site-header">
        <nav class="navbar">
            <div class="container">
                <a href="/" class="site-title">Tsai-Shien Chen</a>
                
                <button class="nav-toggle" id="nav-toggle" aria-label="Toggle navigation">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
                
                <ul class="nav-menu" id="nav-menu">
                    <li><a href="#biography" class="nav-link">Biography</a></li>
                    <li><a href="#experience" class="nav-link">Experience</a></li>
                    <li><a href="#news" class="nav-link">News</a></li>
                    <li><a href="#research" class="nav-link">Research</a></li>
                </ul>
            </div>
        </nav>
    </header>

    <main>
        <section id="home" class="hero-section">
            <div class="hero-background"></div>
            <div class="container">
                <div class="profile-card">
                    <div class="profile-image">
                        <img src="data/images/self-portrait/rainier.jpg" alt="Tsai-Shien Chen" class="avatar">
                    </div>
                    <div class="profile-info">
                        <h1 class="profile-name">Tsai-Shien Chen</h1>
                        <p class="profile-title">Ph.D. Candidate at UC Merced</p>
                        <div class="social-links">
                            <a href="mailto:tsaishienchen@gmail.com" class="social-link" title="Email">
                                <i class="fa fa-envelope"></i>
                            </a>
                            <a href="data/cv/cv.pdf" class="social-link" title="CV">
                                <i class="ai ai-cv"></i>
                            </a>
                            <a href="https://scholar.google.com/citations?user=jRsSebwAAAAJ" class="social-link" title="Google Scholar">
                                <i class="ai ai-google-scholar"></i>
                            </a>
                            <a href="https://x.com/tsaishien_chen" class="social-link" title="Twitter">
                                <i class="fa-brands fa-x-twitter"></i>
                            </a>
                            <a href="https://www.linkedin.com/in/tsaishien-chen/" class="social-link" title="LinkedIn">
                                <i class="fa-brands fa-linkedin-in"></i>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
            <p class="hero-caption">
              Captured at the stunning Santa Monica Beach, where I spent the summers of 2023 through 2025.
            </p>
        </section>

        <section id="biography" class="section">
            <div class="container">
                <div class="content-grid">
                    <div class="biography-content">
                        <h2 class="section-title">
                            <i class="fa fa-id-card"></i>
                            Biography
                        </h2>
                        <div class="bio-text">
                            <p>
                                Welcome! I am a fourth-year Ph.D. candidate at 
                                <a href="https://www.ucmerced.edu/">UC Merced</a>, 
                                advised by Prof. <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>. 
                                I am also a research intern at <a href="https://research.snap.com/team/creative-vision">Snap Creative Vision</a> team, where I am 
                                privileged to work with <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>, 
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>, 
                                <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>, and
                                <a href="https://kfiraberman.github.io/">Kfir Aberman</a>. Previously, I did my 
                                M.S. and B.S. at <a href="http://www.ntu.edu.tw/english/index.html">National Taiwan University</a>. 
                            </p>
                            <p>
                                My research centers on controllable and personalized image and video synthesis, aiming to enable more immersive and intuitive content creation.
                                <!-- My research centers on foundational and personalization models in Generative AI, which I see as cornerstones for bridging the power of AI agents with human creativity. Ultimately, I aim to enable more immersive and intuitive content creation. -->
                            </p>
                            <p>
                                <strong><span class="news-label">NEW!</span> Deeply honored to be awarded the <a href="https://research.google/programs-and-events/phd-fellowship/recipients/?filtertab=2025">2025 Google PhD Fellowship</a>.</strong><br>
                                <strong><span class="news-label">NEW!</span> Looking for research internship positions starting from 2026.</strong>
                            </p>
                        </div>
                    </div>

                    <div id="experience" class="experience-timeline">
                        <div class="timeline">
                            <div class="timeline-item">
                                <div class="timeline-icon">
                                    <img src="data/images/icon/snap.png" alt="Snap" class="company-logo">
                                </div>
                                <div class="timeline-content">
                                    <div class="timeline-date">2023 May - Now</div>
                                    <h3 class="timeline-title">Research Intern @ Snap</h3>
                                    <p class="timeline-desc">
                                        <a href="https://research.snap.com/team/creative-vision">Creative Vision Team</a>
                                    </p>
                                </div>
                            </div>

                            <div class="timeline-item">
                                <div class="timeline-icon">
                                    <img src="data/images/icon/ucmerced.png" alt="UC Merced" class="company-logo">
                                </div>
                                <div class="timeline-content">
                                    <div class="timeline-date">2022 Aug. - Now</div>
                                    <h3 class="timeline-title">Ph.D. @ UC Merced</h3>
                                    <p class="timeline-desc">
                                        <a href="http://vllab.ucmerced.edu/">Vision and Learning Lab</a>
                                    </p>
                                </div>
                            </div>

                            <div class="timeline-item">
                                <div class="timeline-icon">
                                    <img src="data/images/icon/ntu.png" alt="NTU" class="company-logo">
                                </div>
                                <div class="timeline-content">
                                    <div class="timeline-date">2019 Sep. - 2022 March</div>
                                    <h3 class="timeline-title">M.S. @ NTU</h3>
                                    <p class="timeline-desc">
                                        <a href="http://media.ee.ntu.edu.tw/">Media IC & System Lab</a>
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="news" class="section news-section">
            <div class="container">
                <div class="news-content-wrapper">
                    <h2 class="section-title">
                        <i class="fa fa-newspaper"></i>
                        News
                    </h2>
                    <div class="news-container">
                        <div class="news-grid">
                            <div class="news-item">
                                <div class="news-date">Dec 2025 <span class="news-label">NEW!</span></div>
                                <div class="news-content">Invited talk at <a href="https://www.aitime.cn/">AI Time</a> on our latest personalization models towards movie generator. Watch on <a href="https://www.bilibili.com/video/BV1bxqdBYEvQ/?spm_id_from=333.1387.homepage.video_card.click">Bilibili</a>.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">Dec 2025 <span class="news-label">NEW!</span></div>
                                <div class="news-content"><a href="https://snap-research.github.io/omni-attribute/">Omni-Attribute</a> and <a href="https://snap-research.github.io/Video-AlcheMinT/">AlcheMinT</a> were released on arXiv.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">Nov 2025 <span class="news-label">NEW!</span></div>
                                <div class="news-content"><a href="https://snap-research.github.io/layercomposer/">LayerComposer</a> and <a href="https://snap-research.github.io/canvas-to-image/">Canvas-to-Image</a> were released on arXiv.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">Oct 2025 <span class="news-label">NEW!</span></div>
                                <div class="news-content">Awarded <a href="https://research.google/programs-and-events/phd-fellowship/recipients/?filtertab=2025">2025 Google PhD Fellowship</a> in Machine Perception.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">July 2025</div>
                                <div class="news-content">Granted two U.S. patents related to a <a href="https://patents.google.com/patent/US20250247586A1/en9">video dataset</a> and a <a href="https://patents.google.com/patent/US20250245897A1/en">video foundation model</a>.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">July 2025</div>
                                <div class="news-content">Invited talk at <a href="https://www.anuttacon.com/">Anuttacon</a> on video datasets, foundation and application models.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">Feb 2025</div>
                                <div class="news-content"><a href="https://snap-research.github.io/open-set-video-personalization/">Video Alchemist</a> was accepted to CVPR 2025.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">June 2024</div>
                                <div class="news-content">Awarded the <a href="https://graduatedivision.ucmerced.edu/financial-support/internal-fellowships/graduate-student-opportunity-program">Graduate Student Opportunity Program</a> fellowship (full tuition).</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">Sep 2024</div>
                                <div class="news-content"><a href="https://snap-research.github.io/VIMI/">VIMI</a> was accepted to EMNLP 2025 in the main conference track.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">Feb 2024</div>
                                <div class="news-content"><a href="https://snap-research.github.io/Panda-70M/">Panda-70M</a> was accepted to CVPR 2024.</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">Feb 2024</div>
                                <div class="news-content"><a href="https://snap-research.github.io/snapvideo/">Snap Video</a> was accepted to CVPR 2024 as a highlight presentation (2.8% acceptance rate).</div>
                            </div>
                            <div class="news-item">
                                <div class="news-date">May 2023</div>
                                <div class="news-content">Joined the <a href="https://research.snap.com/team/creative-vision">Snap Creative Vision</a> team as a research intern.</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section id="research" class="section publications-section">
            <div class="container">
                <h2 class="section-title">
                    <i class="fa fa-file"></i>
                    Selected Projects
                </h2>
                <p class="section-subtitle">
                    Check the full publication list in <a href="data/cv/cv.pdf">CV</a>
                </p>

                <div class="publications-grid">
                    <article class="publication">
                        <div class="pub-media">
                            <video autoplay loop muted playsinline>
                                <source src="data/research_projects/Omni-Attribute/teaser.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization</h3>
                            <div class="pub-authors">
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>,
                                <a href="https://guochengqian.github.io/">Guocheng Gordon Qian</a>,
                                <a href="https://wangkua1.github.io/">Kuan-Chieh Jackson Wang</a>,
                                <a href="https://scholar.google.com/citations?user=DduS6GQAAAAJ/">Egor Nemchinov</a>,
                                <a href="https://moayedha.com/">Moayed Haji-Ali</a>,
                                <a href="https://alpguler.com/">Riza Alp Guler</a>,
                                <a href="https://www.willimenapace.com/">Willi Menapace</a>,
                                <a href="https://skor.sh/">Ivan Skorokhodov</a>,
                                <a href="https://anilkagak2.github.io/">Anil Kag</a>,
                                <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>,
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>
                            </div>
                            <div class="pub-venue">
                                <em>arXiv preprint 2025</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://snap-research.github.io/omni-attribute/" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2512.10955" class="pub-link">arXiv</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <video autoplay loop muted playsinline>
                                <source src="data/research_projects/AlcheMint/teaser.mov" type="video/mp4">
                            </video>
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation</h3>
                            <div class="pub-authors">
                                <a href="https://sharath-girish.github.io/">Sharath Girish</a>,
                                <a href="https://www.linkedin.com/in/vvivanov/">Viacheslav Ivanov</a>,
                                <strong>Tsai-Shien Chen</strong>,
                                Hao Chen,
                                <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>,
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>
                            </div>
                            <div class="pub-venue">
                                <em>arXiv preprint 2025</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://snap-research.github.io/Video-AlcheMinT/" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2512.10943" class="pub-link">arXiv</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <video autoplay loop muted playsinline>
                                <source src="data/research_projects/Canvas-to-Image/teaser.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Canvas-to-Image: Compositional Image Generation with Multimodal Controls</h3>
                            <div class="pub-authors">
                                <a href="https://yusufdalva.github.io/">Yusuf Dalva</a>,
                                <a href="https://guochengqian.github.io/">Guocheng Gordon Qian</a>,
                                <a href="https://mayagoldenberg.framer.website/">Maya Goldenberg</a>,
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://kfiraberman.github.io/">Kfir Aberman</a>,
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>,
                                <a href="https://pinguar.org/">Pinar Yanardag</a>,
                                <a href="https://wangkua1.github.io/">Kuan-Chieh Jackson Wang</a>
                            </div>
                            <div class="pub-venue">
                                <em>arXiv preprint 2025</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://snap-research.github.io/canvas-to-image/" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2511.21691" class="pub-link">arXiv</a>
                            </div>
                        </div>
                    </article>
                    
                    <article class="publication">
                        <div class="pub-media">
                            <video autoplay loop muted playsinline>
                                <source src="data/research_projects/LayerComposer/teaser.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">LayerComposer: Multi-Human Personalized Generation via Layered Canvas</h3>
                            <div class="pub-authors">
                                <a href="https://guochengqian.github.io/">Guocheng Gordon Qian</a>,
                                <a href="https://ruihangzhang97.github.io/">Ruihang Zhang</a>,
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://yusufdalva.github.io/">Yusuf Dalva</a>,
                                <a href="https://scholar.google.com/citations?user=Pm9ZueEAAAAJ">Anujraaj Argo Goyal</a>,
                                <a href="https://www.willimenapace.com/">Willi Menapace</a>,
                                <a href="https://skor.sh/">Ivan Skorokhodov</a>,
                                <a href="https://www.linkedin.com/in/meng-dong-744a69129/">Meng Dong</a>,
                                <a href="https://scholar.google.com/citations?user=IK3yBTYAAAAJ">Arpit Sahni</a>,
                                <a href="https://scholar.google.com/citations?user=uD79u6oAAAAJ">Daniil Ostashev</a>,
                                <a href="https://scholar.google.com/citations?user=ozJiSMcAAAAJ">Ju Hu</a>,
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>,
                                <a href="https://wangkua1.github.io/">Kuan-Chieh Jackson Wang</a>
                            </div>
                            <div class="pub-venue">
                                <em>arXiv preprint 2025</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://snap-research.github.io/layercomposer" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2510.20820" class="pub-link">arXiv</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <video autoplay loop muted playsinline>
                                <source src="data/research_projects/Video-Alchemist/teaser.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Multi-subject Open-set Personalization in Video Generation</h3>
                            <div class="pub-authors">
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>,
                                <a href="https://www.willimenapace.com/">Willi Menapace</a>,
                                <a href="https://yuwfan.github.io/">Yuwei Fang</a>,
                                <a href="https://www.linkedin.com/in/kwotsin/">Kwot Sin Lee</a>,
                                <a href="https://skor.sh/">Ivan Skorokhodov</a>,
                                <a href="https://kfiraberman.github.io/">Kfir Aberman</a>,
                                <a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a>,
                                <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>,
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>
                            </div>
                            <div class="pub-venue">
                                <em>CVPR 2025</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://snap-research.github.io/open-set-video-personalization/" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2501.06187" class="pub-link">arXiv</a>
                                <a href="https://github.com/snap-research/MSRVTT-Personalization" class="pub-link">code</a>
                                <a href="https://youtu.be/t2lpoMVrtA8" class="pub-link">video</a>
                                <a href="data/research_projects/Video-Alchemist/slides.pdf" class="pub-link">slides</a>
                                <a href="data/research_projects/Video-Alchemist/poster.pdf" class="pub-link">poster</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <video autoplay loop muted playsinline>
                                <source src="data/research_projects/Panda-70M/teaser.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Panda-70M: Captioning 70M Videos with Multiple Cross-Modality Teachers</h3>
                            <div class="pub-authors">
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>,
                                <a href="https://www.willimenapace.com/">Willi Menapace</a>,
                                <a href="https://edeyneka.github.io/">Ekaterina Deyneka</a>,
                                <a href="https://www.linkedin.com/in/hsiang-wei-chao">Hsiang-wei Chao</a>,
                                <a href="https://www.linkedin.com/in/logan-jeon">Byung Eun Jeon</a>,
                                <a href="https://yuwfan.github.io/">Yuwei Fang</a>,
                                <a href="http://hsinyinglee.com/">Hsin-Ying Lee</a>,
                                <a href="https://alanspike.github.io/">Jian Ren</a>,
                                <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>,
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>
                            </div>
                            <div class="pub-venue">
                                <em>CVPR 2024</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://snap-research.github.io/Panda-70M/" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2402.19479" class="pub-link">arXiv</a>
                                <a href="https://github.com/snap-research/Panda-70M" class="pub-link">code</a>
                                <a href="https://youtu.be/m2NQ5k1oTcs" class="pub-link">video</a>
                                <a href="data/research_projects/Panda-70M/slides.pdf" class="pub-link">slides</a>
                                <a href="data/research_projects/Panda-70M/poster.pdf" class="pub-link">poster</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <video autoplay loop muted playsinline>
                                <source src="data/research_projects/SnapVideo/teaser.mp4" type="video/mp4">
                            </video>
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis</h3>
                            <div class="pub-authors">
                                <a href="https://www.willimenapace.com/">Willi Menapace</a>,
                                <a href="https://aliaksandrsiarohin.github.io/aliaksandr-siarohin-website/">Aliaksandr Siarohin</a>,
                                <a href="https://universome.github.io/">Ivan Skorokhodov</a>,
                                <a href="https://edeyneka.github.io/">Ekaterina Deyneka</a>,
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://anilkagak2.github.io/">Anil Kag</a>,
                                <a href="https://yuwfan.github.io/">Yuwei Fang</a>,
                                <a href="https://www.linkedin.com/in/alexeystolyar">Aleksei Stoliar</a>,
                                <a href="https://eliricci.eu/">Elisa Ricci</a>,
                                <a href="https://alanspike.github.io/">Jian Ren</a>,
                                <a href="http://www.stulyakov.com/">Sergey Tulyakov</a>
                            </div>
                            <div class="pub-venue">
                                <em>CVPR 2024</em> <span class="highlight">[Highlight, 2.8% acceptance rate]</span>
                            </div>
                            <div class="pub-links">
                                <a href="https://snap-research.github.io/snapvideo/" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2402.14797" class="pub-link">arXiv</a>
                                <a href="https://youtu.be/aL2zq_IKSBg" class="pub-link">video</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <img src="data/research_projects/MCDiff/teaser.gif" alt="MCDiff teaser">
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Motion-Conditioned Diffusion Model for Controllable Video Synthesis</h3>
                            <div class="pub-authors">
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://hubert0527.github.io/">Chieh Hubert Lin</a>,
                                <a href="https://hytseng0509.github.io/">Hung-Yu Tseng</a>,
                                <a href="https://tsungyilin.info/">Tsung-Yi Lin</a>,
                                <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                            </div>
                            <div class="pub-venue">
                                <em>arXiv preprint 2023</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://tsaishien-chen.github.io/MCDiff/" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2304.14404" class="pub-link">arXiv</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <img src="data/research_projects/IFND/teaser.gif" alt="IFND teaser">
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Incremental False Negative Detection for Contrastive Learning</h3>
                            <div class="pub-authors">
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://hfslyc.github.io/">Wei-Chih Hung</a>,
                                <a href="https://hytseng0509.github.io/">Hung-Yu Tseng</a>,
                                <a href="http://www.ee.ntu.edu.tw/profile1.php?teacher_id=943013&p=3">Shao-Yi Chien</a>,
                                <a href="http://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a>
                            </div>
                            <div class="pub-venue">
                                <em>ICLR 2022</em>
                            </div>
                            <div class="pub-links">
                                <a href="https://openreview.net/forum?id=dDjSKKA5TP1" class="pub-link">OpenReview</a>
                                <a href="https://arxiv.org/abs/2106.03719" class="pub-link">arXiv</a>
                                <a href="data/research_projects/IFND/slides.pdf" class="pub-link">slides</a>
                                <a href="data/research_projects/IFND/poster.pdf" class="pub-link">poster</a>
                            </div>
                        </div>
                    </article>

                    <article class="publication">
                        <div class="pub-media">
                            <img src="data/research_projects/SPAN/teaser.png" alt="SPAN teaser">
                        </div>
                        <div class="pub-content">
                            <h3 class="pub-title">Orientation-aware Vehicle Re-identification with Semantics-guided Part Attention Network</h3>
                            <div class="pub-authors">
                                <strong>Tsai-Shien Chen</strong>,
                                <a href="https://jackie840129.github.io/">Chih-Ting Liu</a>,
                                <a href="https://www.linkedin.com/in/chih-wei-wu-4b5887165/">Chih-Wei Wu</a>,
                                <a href="http://www.ee.ntu.edu.tw/profile1.php?teacher_id=943013&p=3">Shao-Yi Chien</a>
                            </div>
                            <div class="pub-venue">
                                <em>ECCV 2020</em> <span class="highlight">[Oral, 2.1% acceptance rate]</span>
                            </div>
                            <div class="pub-links">
                                <a href="https://tsaishien-chen.github.io/SPAN" class="pub-link">website</a>
                                <a href="https://arxiv.org/abs/2008.11423" class="pub-link">arXiv</a>
                                <a href="https://github.com/tsaishien-chen/SPAN" class="pub-link">code</a>
                                <a href="https://youtu.be/gHBnue6U1Ec" class="pub-link">video</a>
                                <a href="data/research_projects/SPAN/slides.pdf" class="pub-link">slides</a>
                            </div>
                        </div>
                    </article>
                </div>
            </div>
        </section>
    </main>

    <footer class="site-footer">
        <div class="container">
            <div class="footer-content">
                <div class="footer-info">
                    <h3>Visitor Map</h3>
                </div>
            </div>
            <div class="visitor-map">
                <div style="height: 270px; pointer-events: none; max-width: 100%; overflow: hidden;">
                    <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=400&t=tt&d=2ClFWNCR9oPMZcFWYM3X_GeBzFaI0mPZQ4radrEgSBs&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
                </div>
            </div>
        </div>
    </footer>

    <button class="back-to-top" id="back-to-top" aria-label="Back to top">
        <i class="fa fa-arrow-up"></i>
    </button>

    <script>
        document.addEventListener('DOMContentLoaded',
        function() {
            // Mobile navigation toggle
            const navToggle = document.getElementById('nav-toggle');
            const navMenu = document.getElementById('nav-menu');
            
            navToggle.addEventListener('click',
            function() {
                navMenu.classList.toggle('active');
                navToggle.classList.toggle('active');
            });
            
            // Close mobile menu when clicking on a link
            document.querySelectorAll('.nav-link').forEach(link => {
                link.addEventListener('click',
                function() {
                    navMenu.classList.remove('active');
                    navToggle.classList.remove('active');
                });
            });
            
            // Back to top functionality
            const backToTop = document.getElementById('back-to-top');
            
            window.addEventListener('scroll',
            function() {
                if (window.pageYOffset > 300) {
                    backToTop.classList.add('visible');
                } else {
                    backToTop.classList.remove('visible');
                }
            });
            
            backToTop.addEventListener('click',
            function() {
                window.scrollTo({
                    top: 0,
                    behavior: 'smooth'
                });
            });
            
            // Smooth scrolling for navigation links
            document.querySelectorAll('a[href^="#"]').forEach(anchor => {
                anchor.addEventListener('click',
                    function(e) {
                    e.preventDefault();
                    const target = document.querySelector(this.getAttribute('href'));
                    if (target) {
                        target.scrollIntoView({
                            behavior: 'smooth',
                            block: 'start'
                        });
                    }
                });
            });
        });
        
        // Google Analytics
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        
        ga('create',
'UA-60071442-1',
'auto');
        ga('send',
'pageview');
    </script>
</body>
</html>
